# Efficient Storage
To take adavantage of Spark we need to store our data in an efficient manner.
1. Non-human readable
2. Clever storage scheme

## [from resources](https://spoddutur.github.io/spark-notes/deep_dive_into_storage_formats.html) 
![](https://github.com/UVA-DSI/Open-Data-Lab/blob/master/education/Spark19SpDS6003-001/26983627-187e1384-4d5a-11e7-9856-2ae5d20071c6.png)

## Parquet
"Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language." ~https://parquet.apache.org/
