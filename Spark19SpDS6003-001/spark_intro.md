# Introduction

## What is Spark?
* "Apache Sparkâ„¢ is a unified analytics engine for large-scale data processing." ~https://spark.apache.org/
* "Apache Spark is an open-source, distributed processing system used for big data workloads." ~https://aws.amazon.com
* "Apache Spark is an open-source distributed general-purpose cluster-computing framework." ~https://en.wikipedia.org/

## What should I use Spark for?
* "MLlib is Apache Spark's scalable machine learning library." ~https://spark.apache.org/

## A little history (from wiki)
* 2009: UC Berkeley's AMPLab
* 2010: open sourced under a BSD license
* 2013: donated to the Apache Software Foundation and switched its license to Apache 2.0
* 2018-11-02: current release 2.4.0

## Spark Workflow
1. Setup a context
2. Use the context to create data frames
3. Apply operations to extract results

* nb: we will get into data frame operations next time
* nb: we will get into other workflows (ML) the time after next

## pyspark API
* https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql
